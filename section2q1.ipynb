{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = load_dataset(\"gabrielchua/off-topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system_prompt', 'prompt', 'off_topic'],\n",
       "        num_rows: 2642164\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a pandas DataFrame\n",
    "train_df = pd.DataFrame(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2642164 entries, 0 to 2642163\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   system_prompt  object\n",
      " 1   prompt         object\n",
      " 2   off_topic      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 60.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_prompt     61\n",
      "prompt           182\n",
      "off_topic          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in each column\n",
    "missing_values = train_df.isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing missing values: 2642164\n",
      "Number of rows after removing missing values: 2641922\n",
      "Number of rows removed: 242\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove rows with missing values\n",
    "initial_rows = train_df.shape[0]\n",
    "train_df_cleaned = train_df.dropna(subset=['system_prompt', 'prompt'])\n",
    "final_rows = train_df_cleaned.shape[0]\n",
    "rows_removed = initial_rows - final_rows\n",
    "\n",
    "print(f\"Number of rows before removing missing values: {initial_rows}\")\n",
    "print(f\"Number of rows after removing missing values: {final_rows}\")\n",
    "print(f\"Number of rows removed: {rows_removed}\")\n",
    "\n",
    "# Randomly sample 10,000 rows for faster prototyping\n",
    "train_df_cleaned = train_df_cleaned.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Combine system_prompt and prompt\n",
    "train_df_cleaned['combined_prompt'] = train_df_cleaned['system_prompt'] + \" \" + train_df_cleaned['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>off_topic</th>\n",
       "      <th>combined_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879561</th>\n",
       "      <td>Imagine you are an enlightened educator helpin...</td>\n",
       "      <td>Provide tips on improving speed and accuracy i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Imagine you are an enlightened educator helpin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809636</th>\n",
       "      <td>Act as a performance review advisor for team l...</td>\n",
       "      <td>Suggest ways to improve employee communication...</td>\n",
       "      <td>0</td>\n",
       "      <td>Act as a performance review advisor for team l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694452</th>\n",
       "      <td>As an email etiquette expert, assist users in ...</td>\n",
       "      <td>What's a good subject line for networking?</td>\n",
       "      <td>0</td>\n",
       "      <td>As an email etiquette expert, assist users in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929866</th>\n",
       "      <td>Develop a professional networking assistant th...</td>\n",
       "      <td>What are the best practices for maintaining a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Develop a professional networking assistant th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327925</th>\n",
       "      <td>Generate engaging SEO-optimized blog posts for...</td>\n",
       "      <td>What are the health advantages of reducing sug...</td>\n",
       "      <td>0</td>\n",
       "      <td>Generate engaging SEO-optimized blog posts for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878551</th>\n",
       "      <td>You're an expert digital marketing consultant,...</td>\n",
       "      <td>How can I create a viral social media campaign?</td>\n",
       "      <td>0</td>\n",
       "      <td>You're an expert digital marketing consultant,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321864</th>\n",
       "      <td>You are a Health and Fitness Coach Bot designe...</td>\n",
       "      <td>Can you explain how to bypass security on my p...</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a Health and Fitness Coach Bot designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026597</th>\n",
       "      <td>You are a virtual assistant designed to help u...</td>\n",
       "      <td>What's the latest political gossip in my area?</td>\n",
       "      <td>1</td>\n",
       "      <td>You are a virtual assistant designed to help u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105301</th>\n",
       "      <td>Engage with me as your travel advisory compani...</td>\n",
       "      <td>Can you suggest a wildlife-friendly safari exp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Engage with me as your travel advisory compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994009</th>\n",
       "      <td>Adopting the identity of a Creative Writing Me...</td>\n",
       "      <td>Plan an itinerary for a road trip across Europe.</td>\n",
       "      <td>1</td>\n",
       "      <td>Adopting the identity of a Creative Writing Me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             system_prompt  \\\n",
       "879561   Imagine you are an enlightened educator helpin...   \n",
       "1809636  Act as a performance review advisor for team l...   \n",
       "694452   As an email etiquette expert, assist users in ...   \n",
       "1929866  Develop a professional networking assistant th...   \n",
       "2327925  Generate engaging SEO-optimized blog posts for...   \n",
       "...                                                    ...   \n",
       "878551   You're an expert digital marketing consultant,...   \n",
       "2321864  You are a Health and Fitness Coach Bot designe...   \n",
       "1026597  You are a virtual assistant designed to help u...   \n",
       "2105301  Engage with me as your travel advisory compani...   \n",
       "994009   Adopting the identity of a Creative Writing Me...   \n",
       "\n",
       "                                                    prompt  off_topic  \\\n",
       "879561   Provide tips on improving speed and accuracy i...          0   \n",
       "1809636  Suggest ways to improve employee communication...          0   \n",
       "694452          What's a good subject line for networking?          0   \n",
       "1929866  What are the best practices for maintaining a ...          0   \n",
       "2327925  What are the health advantages of reducing sug...          0   \n",
       "...                                                    ...        ...   \n",
       "878551     How can I create a viral social media campaign?          0   \n",
       "2321864  Can you explain how to bypass security on my p...          1   \n",
       "1026597     What's the latest political gossip in my area?          1   \n",
       "2105301  Can you suggest a wildlife-friendly safari exp...          0   \n",
       "994009    Plan an itinerary for a road trip across Europe.          1   \n",
       "\n",
       "                                           combined_prompt  \n",
       "879561   Imagine you are an enlightened educator helpin...  \n",
       "1809636  Act as a performance review advisor for team l...  \n",
       "694452   As an email etiquette expert, assist users in ...  \n",
       "1929866  Develop a professional networking assistant th...  \n",
       "2327925  Generate engaging SEO-optimized blog posts for...  \n",
       "...                                                    ...  \n",
       "878551   You're an expert digital marketing consultant,...  \n",
       "2321864  You are a Health and Fitness Coach Bot designe...  \n",
       "1026597  You are a virtual assistant designed to help u...  \n",
       "2105301  Engage with me as your travel advisory compani...  \n",
       "994009   Adopting the identity of a Creative Writing Me...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating keyword overlap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 70176.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prompt length...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 1400809.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature Engineering - Adding Keyword Overlap and Length of Prompt\n",
    "# Enable tqdm progress bar for pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Function to calculate keyword overlap between system_prompt and prompt\n",
    "def keyword_overlap(system_prompt, prompt):\n",
    "    system_keywords = set(system_prompt.split())\n",
    "    prompt_words = set(prompt.split())\n",
    "    return len(system_keywords.intersection(prompt_words))\n",
    "\n",
    "# Apply keyword overlap with progress bar\n",
    "print(\"Calculating keyword overlap...\")\n",
    "train_df_cleaned['keyword_overlap'] = train_df_cleaned.progress_apply(lambda x: keyword_overlap(x['system_prompt'], x['prompt']), axis=1)\n",
    "\n",
    "# Apply prompt length calculation with progress bar\n",
    "print(\"Calculating prompt length...\")\n",
    "train_df_cleaned['prompt_length'] = train_df_cleaned['prompt'].progress_apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for system_prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [07:37<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:45<00:00, 35.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarity between system_prompt and prompt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 5614864.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Semantic Embedding using DistilBERT and Cosine Similarity\n",
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to generate DistilBERT embeddings for a given text\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Add tqdm progress bar for system_prompt and prompt embeddings\n",
    "tqdm.pandas()  # Enable progress bar for pandas apply\n",
    "\n",
    "# Generate embeddings with progress bar for system_prompt and prompt\n",
    "print(\"Generating embeddings for system_prompt...\")\n",
    "train_df_cleaned['system_prompt_embedding'] = train_df_cleaned['system_prompt'].progress_apply(get_embedding)\n",
    "\n",
    "print(\"Generating embeddings for prompt...\")\n",
    "train_df_cleaned['prompt_embedding'] = train_df_cleaned['prompt'].progress_apply(get_embedding)\n",
    "\n",
    "# Add tqdm progress bar for cosine similarity calculation\n",
    "print(\"Calculating cosine similarity between system_prompt and prompt...\")\n",
    "train_df_cleaned['similarity'] = tqdm(train_df_cleaned.apply(\n",
    "    lambda x: cosine_similarity(x['system_prompt_embedding'], x['prompt_embedding'])[0][0], axis=1), \n",
    "    total=len(train_df_cleaned)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Prepare Final Dataset for Training\n",
    "# Combine the features: TF-IDF of combined_prompt, keyword_overlap, prompt_length, similarity\n",
    "\n",
    "# Step 4.1: Vectorize the combined prompt using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = vectorizer.fit_transform(train_df_cleaned['combined_prompt'])\n",
    "\n",
    "# Convert the sparse TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Step 4.2: Combine the TF-IDF features with keyword overlap, prompt length, and similarity\n",
    "additional_features = train_df_cleaned[['keyword_overlap', 'prompt_length', 'similarity']].reset_index(drop=True)\n",
    "X_features = pd.concat([tfidf_df.reset_index(drop=True), additional_features], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = train_df_cleaned['off_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7000\n",
      "Validation set size: 1500\n",
      "Test set size: 1500\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_features, y, test_size=0.3, random_state=42)  # Split 70% train, 30% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split 50-50 from temp to val and test\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning for Logistic Regression...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   9.1s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   9.2s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   9.9s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=  10.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=  10.1s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   3.4s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=  15.9s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=  16.6s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l1, solver=liblinear; total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=  53.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=  52.6s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=  52.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END .........C=1, max_iter=200, penalty=l1, solver=saga; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=200, penalty=l1, solver=saga; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........C=1, max_iter=200, penalty=l1, solver=saga; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, max_iter=200, penalty=l1, solver=saga; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, max_iter=200, penalty=l1, solver=saga; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=0.1, max_iter=200, penalty=l1, solver=saga; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=10, max_iter=200, penalty=l1, solver=saga; total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=10, max_iter=200, penalty=l1, solver=saga; total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Richmond/Desktop/test/respai/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=10, max_iter=200, penalty=l1, solver=saga; total time= 3.0min\n",
      "Best hyperparameters for Logistic Regression: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 10}\n",
      "Validation Results for Logistic Regression:\n",
      "Accuracy: 0.8220\n",
      "Precision: 0.8207\n",
      "Recall: 0.8011\n",
      "F1 Score: 0.8108\n",
      "\n",
      "Test Results for Logistic Regression:\n",
      "Accuracy: 0.8160\n",
      "Precision: 0.8262\n",
      "Recall: 0.8089\n",
      "F1 Score: 0.8175\n",
      "\n",
      "Starting hyperparameter tuning for Random Forest...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   6.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   7.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   7.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   8.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   8.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=   8.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=  13.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=  15.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   8.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=   7.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   8.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   8.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50; total time=  14.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=  11.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=  10.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=  11.8s\n",
      "Best hyperparameters for Random Forest: {'n_estimators': 100, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Validation Results for Random Forest:\n",
      "Accuracy: 0.8187\n",
      "Precision: 0.8078\n",
      "Recall: 0.8123\n",
      "F1 Score: 0.8101\n",
      "\n",
      "Test Results for Random Forest:\n",
      "Accuracy: 0.8047\n",
      "Precision: 0.8204\n",
      "Recall: 0.7893\n",
      "F1 Score: 0.8045\n",
      "\n",
      "Using default SVM without tuning for SVM\n",
      "Validation Results for SVM:\n",
      "Accuracy: 0.6853\n",
      "Precision: 0.6640\n",
      "Recall: 0.6863\n",
      "F1 Score: 0.6749\n",
      "\n",
      "Test Results for SVM:\n",
      "Accuracy: 0.6860\n",
      "Precision: 0.6905\n",
      "Recall: 0.6950\n",
      "F1 Score: 0.6928\n",
      "\n",
      "Saving the best model (Logistic Regression) with parameters {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 10}...\n",
      "Saving the TF-IDF vectorizer...\n",
      "\n",
      "Best Overall Model Details:\n",
      "Best Model Name: Logistic Regression\n",
      "Best Model F1 Score: 0.8108\n",
      "Best Model Parameters: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 100, 'C': 10}\n",
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 6. Hyperparameter Tuning using GridSearchCV on Validation Set\n",
    "\n",
    "# Define parameter distributions for Logistic Regression and Random Forest\n",
    "param_distributions = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [100, 200]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()  # Default parameters for SVM (no hyperparameter tuning)\n",
    "}\n",
    "\n",
    "# Initialize variables to track the best model across all classifiers\n",
    "best_overall_model = None\n",
    "best_overall_score = 0\n",
    "best_model_name = ''\n",
    "best_model_params = None\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters for Logistic Regression and Random Forest\n",
    "for name, clf in classifiers.items():\n",
    "    if name in [\"Logistic Regression\", \"Random Forest\"]:\n",
    "        print(f\"Starting hyperparameter tuning for {name}...\")\n",
    "\n",
    "        # Perform hyperparameter tuning for Logistic Regression and Random Forest\n",
    "        param_dist = param_distributions[name]\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=clf,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=10,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            cv=3,\n",
    "            verbose=2,\n",
    "            random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "        print(f\"Best hyperparameters for {name}: {random_search.best_params_}\")\n",
    "        best_model = random_search.best_estimator_\n",
    "\n",
    "    else:\n",
    "        # Use default SVM without hyperparameter tuning\n",
    "        clf.fit(X_train, y_train)\n",
    "        best_model = clf\n",
    "        print(f\"Using default SVM without tuning for {name}\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Evaluate performance on validation set\n",
    "    accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "    precision_val = precision_score(y_val, y_val_pred)\n",
    "    recall_val = recall_score(y_val, y_val_pred)\n",
    "    f1_val = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"Validation Results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "    print(f\"Precision: {precision_val:.4f}\")\n",
    "    print(f\"Recall: {recall_val:.4f}\")\n",
    "    print(f\"F1 Score: {f1_val:.4f}\\n\")\n",
    "\n",
    "    # Keep track of the best model based on the F1 score on the validation set\n",
    "    if f1_val > best_overall_score:\n",
    "        best_overall_score = f1_val\n",
    "        best_overall_model = best_model\n",
    "        best_model_name = name\n",
    "        best_model_params = random_search.best_params_ if name in [\"Logistic Regression\", \"Random Forest\"] else \"Default SVM parameters\"\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Test Results for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "    print(f\"Precision: {precision_test:.4f}\")\n",
    "    print(f\"Recall: {recall_test:.4f}\")\n",
    "    print(f\"F1 Score: {f1_test:.4f}\\n\")\n",
    "\n",
    "# Save the best model and vectorizer\n",
    "print(f\"Saving the best model ({best_model_name}) with parameters {best_model_params}...\")\n",
    "joblib.dump(best_overall_model, 'off_topic_detector/models/off_topic_model.pkl')\n",
    "\n",
    "print(\"Saving the TF-IDF vectorizer...\")\n",
    "joblib.dump(vectorizer, 'off_topic_detector/models/tfidf_vectorizer.pkl')\n",
    "\n",
    "# Print out the details of the best model\n",
    "print(\"\\nBest Overall Model Details:\")\n",
    "print(f\"Best Model Name: {best_model_name}\")\n",
    "print(f\"Best Model F1 Score: {best_overall_score:.4f}\")\n",
    "print(f\"Best Model Parameters: {best_model_params}\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "respai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
